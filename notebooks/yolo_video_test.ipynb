{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Object Detection and Tracking in Video Using YOLO and ByteTrack\n",
    "\n",
    "This notebook demonstrates how to perform object detection and tracking in a video using the YOLO (You Only Look Once) model and the ByteTrack algorithm. The process involves loading a pre-trained YOLO model, applying it to each frame of a video, and tracking the detected objects across frames. The annotated video is then displayed with bounding boxes and labels for the detected objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 persons, 27.4ms\n",
      "Speed: 4.8ms preprocess, 27.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 21.3ms\n",
      "Speed: 4.4ms preprocess, 21.3ms inference, 6.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 19.2ms\n",
      "Speed: 2.3ms preprocess, 19.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 11.0ms\n",
      "Speed: 2.4ms preprocess, 11.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 11.9ms\n",
      "Speed: 2.3ms preprocess, 11.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 14.9ms\n",
      "Speed: 2.6ms preprocess, 14.9ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 13.5ms\n",
      "Speed: 1.8ms preprocess, 13.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 12.2ms\n",
      "Speed: 1.9ms preprocess, 12.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 9.7ms\n",
      "Speed: 1.9ms preprocess, 9.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 13.0ms\n",
      "Speed: 2.6ms preprocess, 13.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 11.3ms\n",
      "Speed: 2.6ms preprocess, 11.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 14.0ms\n",
      "Speed: 2.6ms preprocess, 14.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 13.0ms\n",
      "Speed: 1.9ms preprocess, 13.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 11.8ms\n",
      "Speed: 1.9ms preprocess, 11.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 15.2ms\n",
      "Speed: 2.1ms preprocess, 15.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 10.8ms\n",
      "Speed: 1.9ms preprocess, 10.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 10.5ms\n",
      "Speed: 1.9ms preprocess, 10.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 10.8ms\n",
      "Speed: 1.7ms preprocess, 10.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 10.1ms\n",
      "Speed: 1.8ms preprocess, 10.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 15.8ms\n",
      "Speed: 2.4ms preprocess, 15.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 13.9ms\n",
      "Speed: 1.9ms preprocess, 13.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 10.8ms\n",
      "Speed: 1.7ms preprocess, 10.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 11.2ms\n",
      "Speed: 1.6ms preprocess, 11.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 10.8ms\n",
      "Speed: 1.8ms preprocess, 10.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 13.8ms\n",
      "Speed: 2.4ms preprocess, 13.8ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 13.7ms\n",
      "Speed: 2.0ms preprocess, 13.7ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 11.1ms\n",
      "Speed: 2.0ms preprocess, 11.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 19.5ms\n",
      "Speed: 2.0ms preprocess, 19.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 11.4ms\n",
      "Speed: 1.9ms preprocess, 11.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 13.6ms\n",
      "Speed: 2.0ms preprocess, 13.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 14.8ms\n",
      "Speed: 1.9ms preprocess, 14.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 11.1ms\n",
      "Speed: 2.0ms preprocess, 11.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 11.2ms\n",
      "Speed: 1.8ms preprocess, 11.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 12.1ms\n",
      "Speed: 1.8ms preprocess, 12.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 14.4ms\n",
      "Speed: 1.7ms preprocess, 14.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 11.7ms\n",
      "Speed: 1.8ms preprocess, 11.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 13.5ms\n",
      "Speed: 1.9ms preprocess, 13.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 12.3ms\n",
      "Speed: 1.7ms preprocess, 12.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 11.0ms\n",
      "Speed: 1.9ms preprocess, 11.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 11.8ms\n",
      "Speed: 1.8ms preprocess, 11.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 15.1ms\n",
      "Speed: 1.9ms preprocess, 15.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 14.4ms\n",
      "Speed: 1.7ms preprocess, 14.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 11.6ms\n",
      "Speed: 1.9ms preprocess, 11.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 10.9ms\n",
      "Speed: 2.3ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 12.2ms\n",
      "Speed: 1.9ms preprocess, 12.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 14.1ms\n",
      "Speed: 2.4ms preprocess, 14.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 13.0ms\n",
      "Speed: 2.2ms preprocess, 13.0ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 10.9ms\n",
      "Speed: 1.7ms preprocess, 10.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 13.7ms\n",
      "Speed: 2.2ms preprocess, 13.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 13.8ms\n",
      "Speed: 1.9ms preprocess, 13.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 11.2ms\n",
      "Speed: 2.0ms preprocess, 11.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 18.9ms\n",
      "Speed: 1.9ms preprocess, 18.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 11.8ms\n",
      "Speed: 1.8ms preprocess, 11.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 12.7ms\n",
      "Speed: 1.7ms preprocess, 12.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 17.6ms\n",
      "Speed: 2.2ms preprocess, 17.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 shuttle, 14.2ms\n",
      "Speed: 2.1ms preprocess, 14.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 19.9ms\n",
      "Speed: 3.0ms preprocess, 19.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 14.5ms\n",
      "Speed: 2.5ms preprocess, 14.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 shuttle, 18.9ms\n",
      "Speed: 2.3ms preprocess, 18.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 12.9ms\n",
      "Speed: 2.7ms preprocess, 12.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 13.0ms\n",
      "Speed: 2.5ms preprocess, 13.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 16.3ms\n",
      "Speed: 2.5ms preprocess, 16.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 12.6ms\n",
      "Speed: 2.7ms preprocess, 12.6ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 12.9ms\n",
      "Speed: 2.1ms preprocess, 12.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 11.8ms\n",
      "Speed: 2.1ms preprocess, 11.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 10.9ms\n",
      "Speed: 1.9ms preprocess, 10.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 11.3ms\n",
      "Speed: 1.9ms preprocess, 11.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 12.0ms\n",
      "Speed: 1.8ms preprocess, 12.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 11.2ms\n",
      "Speed: 2.6ms preprocess, 11.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "import supervision as sv\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "\n",
    "# Configuration\n",
    "CONFIG = {\n",
    "    \"VIDEO_PATH\": \"../data/videos/input/badminton_test.mp4\",  # Path to the input video\n",
    "    \"MODEL_PATH\": \"../weights/badminton_best.pt\",  # Path to the YOLO model weights\n",
    "    \"CONFIDENCE_THRESHOLD\": 0.5,  # Confidence threshold for detections\n",
    "    \"DEVICE\": \"cuda:0\",  # Device to run the model on (e.g., 'cuda:0' for GPU or 'cpu' for CPU)\n",
    "    \"DISPLAY_RESOLUTION\": (1280, 720),  # Resolution for displaying the annotated video\n",
    "    \"FPS_MONITOR_ENABLED\": True,  # Enable or disable FPS monitoring\n",
    "}\n",
    "\n",
    "# Load YOLO model\n",
    "model = YOLO(CONFIG[\"MODEL_PATH\"], task='detect')\n",
    "\n",
    "# Initialize FPS monitor\n",
    "fps_monitor = sv.FPSMonitor()\n",
    "\n",
    "# Initialize tracker and annotators\n",
    "tracker = sv.ByteTrack()\n",
    "box_annotator = sv.BoxAnnotator()\n",
    "label_annotator = sv.LabelAnnotator()\n",
    "\n",
    "# Get video frame generator\n",
    "frame_generator = sv.get_video_frames_generator(source_path=CONFIG[\"VIDEO_PATH\"])\n",
    "\n",
    "# Process and display each frame of the video\n",
    "for frame in frame_generator:\n",
    "    # Perform prediction with YOLO model\n",
    "    results = model.predict(frame, conf=CONFIG[\"CONFIDENCE_THRESHOLD\"], device=CONFIG[\"DEVICE\"])[0]\n",
    "    detections = sv.Detections.from_ultralytics(results)\n",
    "\n",
    "    # Update detections with tracker\n",
    "    detections = tracker.update_with_detections(detections)\n",
    "\n",
    "    # Annotate the frame with bounding boxes and labels\n",
    "    annotated_image = box_annotator.annotate(scene=frame.copy(), detections=detections)\n",
    "\n",
    "    annotated_image = label_annotator.annotate(\n",
    "        scene=annotated_image,\n",
    "        detections=detections\n",
    "    )\n",
    "    # Generate FPS and annotate the frame\n",
    "    if CONFIG[\"FPS_MONITOR_ENABLED\"]:\n",
    "        fps_monitor.tick()\n",
    "        fps = fps_monitor.fps\n",
    "        cv2.putText(annotated_image, f\"FPS: {fps:.2f}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "    # Resize the annotated image for display\n",
    "    annotated_image = cv2.resize(annotated_image, CONFIG[\"DISPLAY_RESOLUTION\"])\n",
    "\n",
    "    # Display the annotated frame in a window\n",
    "    cv2.imshow(\"Annotated Video\", annotated_image)\n",
    "\n",
    "    # Exit the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources and close windows\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "badmintoncoach",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
